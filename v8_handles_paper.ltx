%&v8_handles_paper_preamble
\endofdump

\begin{document}

\begin{abstract}
The merits of direct and indirect handles for Garbage Collection (GC) have
long been debated. V8 has traditionally used indirect handles to allow
precise garbage collection. In this paper we first show that it is possible
to gradually migrate from (seemingly fundamental) indirect handles to direct
handles. We then migrate a substantial portion of V8 to use direct handles.
For the portion of V8 we have migrated, we show that direct handles are
faster than indirect handles.
\end{abstract}


\maketitle


\section{Introduction}

Like many other modern language runtimes, Chrome's V8 JavaScript engine uses
garbage collection (GC) to manage its dynamically allocated memory. The V8 heap
is managed with a mark-sweep collector, which periodically traces objects, and
then frees those which are unreachable. V8 is often embedded into other
applications, such as Chrome's Blink rendering engine, so its garbage collector
must be able to track objects which are referenced externally through a
(potentially unmanaged) embedder.

V8 developers do not obtain pointers to JavaScript objects directly. Instead
\textit{handles} are used to encode a two-level indirection to JavaScript
objects. A handle acts as a root for garbage collection, where it stores the
pointer to an object in a fixed place in the VM, and developers reference the
object through a pointer to its handle.

The beauty of this scheme is that collectively, handles implicitly encode the
GC’s root set of objects, and JavaScript objects can be moved easily while it
they are still referenced, since only the value stored in a handle needs to be
updated. However, this simplicity comes with a performance cost: each heap
object dereference requires two (nested) pointer dereferences, with inevitable
consequences for code size, cache behaviour, and static optimisations. There is
also a performance cost to creating and destroying the blocks in the VM which
contain these handles. Handles in V8 also have an ergonomic trade-off, they
require V8 developers to respect various rules that cannot be fully encoded in
\cpp's type system. While linting tools are provided to ensure rules around
handles are followed, violations can lead to unsoundness.

\jake{Feel like we need a paragraph here explaining why we decided that we'd
prefer now to add complexity to get the performance}
\laurie{i think the answer is `history'?}

In this paper we describe a practical scheme for gradually migrating V8 from
indirect to direct handles, making such a transition plausible without a single,
disruptive change. We then show that, for the portions of the transition that we
have implemented, direct handles are faster than indirect handles.

This papers contributions are as follows:

\jake{tumbleweed...}

This paper is structured as follows. We first introduce Chrome and its existing
memory management implementation (Section \ref{sec:background}). In Section
\ref{sec:direct_handles} we detail how we switched most parts of V8 to directly
reference JavaScript objects. We show how we use conservative stack scanning to
identify the rootset for garbage collection instead. We evaluate the impact of
both handles and direct references in Section \ref{sec:evaluation}.


\section{Background}
\label{sec:background}
In this section, we give a brief overview of V8 and how its memory management
works.
\subsection{V8 garbage collection basics}
V8 is a high-performance JavaScript virtual machine (VM). It can be used as a
standalone application or embedded into larger applications such as Chrome or
NodeJS using its \cpp API.

V8 has a generational garbage collector with the JavaScript heap split into two
distinct sections for young and old object collection. The smaller young
generation is a Cheney style semi-space scavenger \laurie{cite} divided into two contiguous
fixed size blocks of memory known as \textit{tospace} and \textit{fromspace}.
Objects are bump allocated in fromspace until it is full, at which point live
objects are moved to tospace which becomes the new young generation heap and so
on. Objects which have been moved more than once in the young generation are
promoted to the old generation.

The old generation is a mark-sweep-compact collector. Marking is performed
concurrently to the main thread of JavaScript execution to reduce pause times.
Dijkstra style write barriers \jake{cite} are used when object fields are written to on the
main thread to maintain the tri-colour marking scheme. Sweeping is also
performed concurrently to the main thread and makes use of parallel worker
threads. Surviving objects are then compacted to reduce memory fragmentation.
Compaction is not done concurrently to the main thread, however, in Chrome it
makes use of idle time to reduce the impact of the GC pause.


\subsection{Blink as an API consumer}

Handles (and handle scopes) are internal V8 concepts which are not exposed in
the external API. Instead the API bindings layer exposes locals — a separate
class which mirrors a subset of the indirect handle API. Like indirect handles,
locals use two-level indirection to JavaScript objects, and are converted to
indirect V8 handles when they cross the boundary into the V8 C++ runtime. This
conversion to and from indirect handles takes place through OpenHandle and
ToLocal, respectively.

\subsection{Handle infrastructure}

V8’s current indirect handles have a fairly complex underlying mechanism that is
best explained in stages. Before a V8 programmer can obtain a reference to a
JavaScript object, they must first create a handle scope, which implicitly
becomes the ``active'' handle scope. When a reference to a JavaScript object is
requested, an indirect handle is created, and added to the most recent handle
scope. When the handle scope object is deleted at run-time, all the indirect
handles created since the beginning of the handle scope’s lifetime are deleted
together, and the previous handle scope becomes the active handle scope. At any
point the GC can ask a handle scope to enumerate all the indirect handles it
refers to.

Indirect handles contain a pointer-sized value. That value points to a member of
an intermediate set called a handle block. Handle blocks are never moved in
memory, so pointers to a member of a handle block are always stable. Each member
of a handle block points to a JavaScript object.

V8 makes use of indirect handles to store Small Integer Objects (SMIs), that is
JavaScript integers that are not boxed on the heap. An important case is the SMI
0 and the null pointer: V8 encodes them in a way that allows them to be
efficiently differentiated. Indirect handles that have an internal value of NULL
represent a null pointer (and thus cannot be dereferenced to a handle block
member). Handle block members with an interior value whose least significant bit
is 0 encode a SMI; if the same bit is 1 a pointer is encoded.

\section{Removing Handles}
\label{sec:direct_handles}
\subsection{Direct object pointers}
\subsection{Conservative Stack Scanning}
\section{Evaluation}
\label{sec:evaluation}


\section{Related Work}
\label{sec:related}

The relative merits of direct pointers and handles have a long history in GC
and VMs, though quantitative comparisons are few in number. Generalising
somewhat, one technique or the other has tended to hold sway either at
different points in time, or within different communities.

Handles were commonly used in early Smalltalk VMs \laurie{let's cite at least
one Smalltalk VM using handles, ideally whichever is the earliest we know of}
\laurie{do we know why they were used in Smalltalk VMs? for moving i presume?}. \laurie{let's check
on Self too -- i bet it uses handles}. HotSpot -- the now \emph{de facto}
standard JVM -- uses handles for C++ code \laurie{cite at least the glossary}.
Separately, HotSpot also uses a different kind of handles in the Java Native
Interface (JNI), its foreign function interface. Java objects are added to a
table of registered objects and accessed through a level of indirection when
used externally. The collector treats this table as an additional set of roots.
\laurie{i would not be surprised if the JNI handles are the same as the C++
handles}

\laurie{let's try relate this to our paper}
To the best of our knowledge, the most comprehensive study of handles
is~\cite{kalibera11handles}. They showed how moving handle-based VMs do not suffer
from \textit{copy reserve overhead}, where the old copy of a moved object must
be kept around until the mutator only holds references to the new object
location. Instead, with handles, the space used by evacuated objects can be
reused immediately as only the handle's address needs updating. With careful
optimisations, they showed that a handle-based system has same execution time
overheads as a Brooks-style compacting collector. Some of the ways they describe
that handles can be optimisated are: using \textit{fat handles} to store
commonly accessed header information along with the object pointer; grouping
handles of objects that live and die together to reduce fragmentation in handle
blocks; and short-circuiting handles for pinned objects.

Firefox's JavaScript engine SpiderMonkey uses handles in a similar fashion to
V8~\cite{spidermonkey}. \laurie{i'm not sure which bits of the rest of the
paragraph are different than V8.} Spidermonkey
developers must ensure that each pointer to a JavaScript object on the stack is
registered as root for garbage collection. Additional references to a JavaScript
object can then be created, which access it indirectly through the originally
rooted value. Rooted values are registered in lists based on scope, with
persistent handles available for longer living roots. Handles cannot be stored
on the heap as they could end up outliving their root. SpiderMonkey
uses a static analysis tool to make sure that raw pointers are not accidentally
put on the stack when a garbage collection can take place. The Gecko Rendering
engine is used in firefox. It is written in C++ and manages its DOM heap with
reference counting. It implements a cycle collector based on
\cite{bacon01concurrent}.

The use of direct pointers implicitly requires conservative scanning of at
least the stack. However, most (perhaps all) programming languages and most
(perhaps all) compilers have rules which suggest that conservative stack
scanning is undefined behaviour. Most obviously, there is no way of writing a
conservative stack scanner in C/C++ which is not undefined behaviour. In
practise, fortunately, conservative stack scanning `works', as perhaps best
evidenced by the long history of the Boehm-Demers-Weiser (BDW)
GC~\cite{boehm88garbage} which uses conservative scanning for the stack and
other possible location of GC roots (though note that the first conservative
scanning GC appears to have been~\cite{caplinger88memory}). BDW has been ported
to most platforms in its long history, and used by a wide variety of software
(including relatively modern software such as Inkscape): it is plausible that
its very existence has been the reason why conservative stack scanning
continues to be supported in practise across languages and compilers.

\jake{Should I mention oilpan here? Or is it too
"Chrome" to be considered related?} \laurie{i think it's fine to mention it, though 1 or 2 sentences is probably enough} Other conservative collectors for unmanaged
languages are the .

Safari's underlying engine WebKit (of which the JavaScript VM, JSC, is a part)
use direct pointers and conservative stack scanning~\cite{pizlo17riptide},
which is very similar to what we propose for V8 in this paper. WebKit has had
at least two different GCs over time (the current GC, \cite{pizlo17riptide},
runs in parallel to JavaScript execution, similarly to V8), but this has not
changed the details relevant to this paper. WebKit's GCs move objects; as we
propose for V8, when conservative scanning references an object, that object is
pinned, and cannot be moved. Unlike V8, which uses precise stack scanning use
stackmaps, WebKit uses conservative stack scanning for JIT compiled code, so
there is a marginally increased chance of `accidental' object marking.

\laurie{is there anything novel about this paper w.r.t. handles? if it's just
that it uses handles to allow moving, that seems the same as all the earlier
handle-using systems?}
Compact-fit\cite{craciunas08compacting} is a compacting allocator which uses handles to allow objects to
move. It consists of two conceptual memory layers: the \textit{abstract address
space}; and the \textit{concrete address space}. Direct pointers to objects
allocated in the concrete address space are not possible. The application
operates on pointers to the abstract address space which are managed by handles.
Object headers have back-pointers to their canonical handle.

%TODO: Managed language collectors:
% - Fast CSS: https://users.cecs.anu.edu.au/~steveb/pubs/papers/consrc-oopsla-2014.pdf
% - Hybrid CSS: https://www.usenix.org/legacy/events/jvm01/full_papers/barabash/barabash.pdf
% - Forkscan Reclamation: https://dspace.mit.edu/bitstream/handle/1721.1/123336/forkscan-eurosys-17.pdf
% - Sound GC for C using taint analysis: https://dl.acm.org/doi/pdf/10.1145/3428244

\section{Conclusions}
\label{sec:conclusion}

\cite{jones16garbage}

\bibliographystyle{plain}
\bibliography{bib}

\end{document}
