%&v8_handles_paper_preamble
\endofdump

\begin{document}

\begin{abstract}
The performance merits of using handles or direct references for garbage
collection have long been debated, but there are few published
comparisons. In this paper we provide concrete evidence of the
performance differences between these two approaches by migrating a
substantial portion of V8, a modern JavaScript virtual machine, from
handles to direct references. On standard V8 benchmark suites, the use
of direct references improves performance by \laurie{X\%}.
\end{abstract}


\maketitle


\section{Introduction}

A major challenge with Garbage Collection (GC) is finding all the \emph{roots}
(i.e.~the starting set of references into the object graph). Many languages,
notably C/C++, and many compilers, provide no way to precisely enumerate the
roots. This is a challenge for those programming language Virtual Machines (VMs)
written in C/C++ which implement GCed languages (e.g.~LISP, Java,
or JavaScript): when using \emph{direct references} to objects, roots
can be `lost' on the C/C++ call stack.

Compiler support for \emph{stackmaps} allows precise scanning of the C/C++ call
stack to uncover all direct references: unfortunately, GCC has no support for
stackmaps, and LLVM's support is incomplete and unsupported. In practise,
nearly all VMs thus have to make a choice. If they want to use direct references,
they must use \emph{conservative stack scanning}, which considers every word on
the stack to be a potential pointer: if that `pointer' references a GCed
object, then it is considered to be a root. This over-approximates the
roots: words that are not pointers can accidentally keep alive objects.
\emph{Handles} add a
layer of indirection to object references. A handle is stored at a fixed point
in memory, allowing the \emph{pool} of handles to be easily enumerated as
roots. The object a handle refers to can then move in memory. This provides
accurate enumeration of the roots, but can be awkward to program with.

The relative merits of direct references and handles have been a talking point
in GC research for decades. In particular, many have strong opinions on the
performance of each approach: conservative stack scanning wastes time examining
words that can never be pointers; and handles require two dereferences to reach
an object. However, there is a dearth of performance comparisons since
VMs typically choose at the outset to use one approach or the other.

In this paper we examine the widely used JavaScript VM \emph{V8}, which has
been designed from its inception to use handles. Our fundamental hypothesis is
that moving from handles to direct references will improve V8's performance.
However, moving wholesale from handles to direct references is impractical on a
codebase of V8's size \laurie{how many LoC is V8?}, so our first challenge was
to find a practical means for gradually migrating parts of V8 from handles to
direct references (Section~\ref{sec:migration}). Having then migrated a
substantial portion of V8 from handles to direct references \laurie{can we give
a rough fraction/percentage?}, we then run several standard V8 benchmark
suites, and find that direct references improve performance by \laurie{X\%}
(Section~\ref{sec:evaluation}). We believe this validates our hypothesis in the
context of V8: it may also provide a useful example for other VMs when
considering direct references and handles.


\section{Background}
\label{sec:background}

In this section we provide a brief overview of direct references and handles in
the context of VMs. To help make this somewhat concrete, we do so for a
hypothetical VM, written in C, that implements an object orientated language.
In this VM, every language-level object is an instance of a \texttt{struct} called
\texttt{Obj}, which we will assume has a single field \texttt{data} of type
\texttt{int}. We assume that the GC runs concurrently to the main
VM thread and can free the memory of any unreachable \texttt{Obj} at any point.


\subsection{Direct References}

The most `natural' way to program our hypothetical VM is to use direct
references. Assuming that the GC exposes a single function \texttt{Obj
*gc\_new\_obj()} which returns a pointer to a block of memory with a freshly
initialised \texttt{Obj}, when we want to create a new object, we call
\texttt{gc\_new\_obj}, assign the result to a local variable, and then operate
upon it's \texttt{data} field:

\begin{lstlisting}[language=C]
Obj *n = gc_new_obj();
n.data = 1;
\end{lstlisting}

As this example suggests, when using direct references, we program in C much as we
would for any non-VM C program. However, the concurrent GC poses a potential problem
for this example code, as it can run immediately after line 1 has executed, but
before line 2 has executed. If the GC were to free the block of memory
containing the \texttt{Obj} then something `bad' would happen when line 2 is
executed (e.g.~the program might segfault or overwrite a portion of memory now
used in another part of a program).

The challenge for direct references is that local variables such as \texttt{n}
are normally stored in a function frame on the C call stack\footnote{There are
other hiding places for such references, ranging from thread-local to
intermediate variables: for introductory purposes, they can be considered minor
variations on the C call stack problem.}: somehow, the GC must be able to find
the local variable \texttt{n} on the call stack and use the object it points to
as a root.

The ideal, and universal, solution would be for C's language specification to
allow \emph{introspection} of a function's frame layout, telling it,
for example, where each local variable lives within a frame. For each
frame on the stack, the GC could then read the value of each variable of type \texttt{Obj*}
and add that as a GC root. Local variables of other types, which are not
of interest to the GC, would be ignored. In other words, in this scenario the
GC can precisely enumerate the GC roots. Unfortunately, no mainstream systems language defines an introspection
capability.

Some compilers instead offer the concept of \emph{stackmaps}, where
the compiler defines a way for a program to introspect a function's frame
layout. Stackmaps offer the same functionality as language-defined
introspection, but do so in a way that is not portable between compilers. For
example, GCC does not offer stackmap support. LLVM does have stackmap support,
but (as some of this paper's authors have discovered in other work), it
is experimental, incomplete, and unsupported, with particular problems at
higher optimisation levels.

In practise, therefore, VMs using direct references have to turn to
Conservative Stack Scanning (CSS), where the call stack is exhaustively examined for
pointers to instances of \texttt{Obj}. In order for this to work, the GC must
know at what address a thread's stack began, and what address the stack is
currently at. Each (aligned) word on the stack is then checked to see whether
it references an instance of \texttt{Obj}: if it does, that \texttt{Obj} is
considered a root. Depending on the GC, checking whether an arbitrary word is a
pointer to an \texttt{Obj} can be fairly expensive \laurie{cite?}. CSS also inherently
over-approximates the root set, because random words on the stack may
accidentally point to an \texttt{Obj}, keeping it alive longer than necessary.
Fortunately, in practise few objects are kept alive unnecessarily long:
the most extensive study we know of suggests the false detection rate
in Java programs is under 0.01\% of live objects~\cite{shahriyar14fast}.

Although CSS is widely used in practise (e.g.~the well-known
Boehm-Demers-Weiser GC~\cite{boehm88garbage} and WebKit~\cite{pizlo17riptide}),
there are other issues to consider. First, it occupies something of a moral
grey zone in terms of its safety: it is not possible to write CSS in C without
undefined behaviour; and some compilers can frustrate CSS \laurie{cite the GCC
word-splitting bug}, as can some operating systems. Second, it is impossible to
write a fully \emph{moving GC} (i.e.~a GC which can change the position of an
\texttt{Obj} in memory e.g.~to reduce memory fragmentation) with CSS, because a
conservatively-identified reference to an \texttt{Obj} might not be an actual
reference. In other words, if we were to change conservatively-identified
references to point to new memory locations, we would sometimes change parts of
memory which were never intended to be references to an \texttt{Obj}, breaking
the underlying program.


\subsection{Handles}

An alternative approach to CSS has become known as handles (first introduced in
recognisable form by~\cite{brooks84trading}, though the term `handles' was only
used later). The basic idea is to add a level of indirection to object
references, with the indirection being the `handle'. Handles are stored at a
guaranteed-fixed point in memory, though the \texttt{Obj} a handle points to
may move.

When the VM wants to use a handle, it must register it as being used with the
GC: this ensures the handle is treated as a root; and also temporarily pinning
the underlying \texttt{Obj} to prevent it from being moved, ensuring that
accessing the \texttt{Obj} is safe. When the VM is finished operating on the
\texttt{Obj} it must register the handle as no longer being used, which removes
the handle from the root set, and unpins the underlying \texttt{Obj}.

In our ongoing example, our GC gains a new struct \texttt{Handle} and three new
functions: \texttt{Handle *gc\_new\_obj()} which returns a pointer to a handle,
where the handle points to a freshly initialised \texttt{Obj}; \texttt{Obj
*use\_handle(Handle *)} which informs the GC that the handle being pointed to
is being used, and returns a pointer to the underlying \texttt{Obj}; and
\texttt{void unuse\_handle(Handle *)} which informs the GC that the handle is
no longer being used. For example:

\begin{lstlisting}[language=C]
Handle *h = gc_new_obj();
Obj *o = use_handle(h);
n.data = 1;
unuse_handle(h);
\end{lstlisting}

Handles have significant advantages. First, the \texttt{use} / \texttt{unuse} of a
handle implicitly adds / removes it to / from the GC's root set with perfect
precision. Furthermore, it does so in a way that is fully portable, requires no
explicit language or compiler support, and does not stray into the territory of
possibly undefined behaviour. Second, if a \texttt{Handle} is not currently
used, the underlying \texttt{Obj} can be safely moved. In other words, handles
make it trivial to write moving GCs.

There are however disadvantages. First, any handle API is easy to misuse:
forgetting to \texttt{use} a handle or \texttt{unuse}ing a handle twice leads
to undefined behaviour. Finding such API misuse is notoriously hard, and VMs
such as V8 have developed home-grown linters that scan for obvious API misuse,
though none that we know of can catch all possible kinds of API misuse. Second,
the double indirection that handles imply causes at least some performance loss
relative to the single indirection of direct references. Third, handles have
additional run-time costs beyond those of double indirection: each handle
consumes some memory; since handles cannot move, they can cause memory
fragmentation; and using / unusing a handle requires at least some computation
and, depending on the VM, possibly memory allocation.


\section{Handles in V8}

\laurie{in this section we want to go into detail into V8's handle mechanism,
giving code examples etc. Hopefully it can build upon the simple abstract view
of the Background section, but we shouldn't try and force the description of V8
into that vein if it doesn't fit. I can easily change the Background section to
reflect what will most help the reader understand V8.}

In this section, we give a brief overview of V8 and how its memory management
works.

\subsection{V8 garbage collection basics}
V8 is a high-performance JavaScript virtual machine (VM). It can be used as a
standalone application or embedded into larger applications such as Chrome or
NodeJS using its \cpp API.

V8 has a generational garbage collector with the JavaScript heap split into two
distinct sections for young and old object collection. The smaller young
generation is a Cheney style semi-space scavenger \laurie{cite} divided into two contiguous
fixed size blocks of memory known as \textit{tospace} and \textit{fromspace}.
Objects are bump allocated in fromspace until it is full, at which point live
objects are moved to tospace which becomes the new young generation heap and so
on. Objects which have been moved more than once in the young generation are
promoted to the old generation.

The old generation is a mark-sweep-compact collector. Marking is performed
concurrently to the main thread of JavaScript execution to reduce pause times.
Dijkstra style write barriers \jake{cite} are used when object fields are written to on the
main thread to maintain the tri-colour marking scheme. Sweeping is also
performed concurrently to the main thread and makes use of parallel worker
threads. Surviving objects are then compacted to reduce memory fragmentation.
Compaction is not done concurrently to the main thread, however, in Chrome it
makes use of idle time to reduce the impact of the GC pause.


\subsection{Blink as an API consumer}

Handles (and handle scopes) are internal V8 concepts which are not exposed in
the external API. Instead the API bindings layer exposes locals — a separate
class which mirrors a subset of the indirect handle API. Like indirect handles,
locals use two-level indirection to JavaScript objects, and are converted to
indirect V8 handles when they cross the boundary into the V8 C++ runtime. This
conversion to and from indirect handles takes place through OpenHandle and
ToLocal, respectively.

\subsection{Handle infrastructure}

V8’s current indirect handles have a fairly complex underlying mechanism that is
best explained in stages. Before a V8 programmer can obtain a reference to a
JavaScript object, they must first create a handle scope, which implicitly
becomes the ``active'' handle scope. When a reference to a JavaScript object is
requested, an indirect handle is created, and added to the most recent handle
scope. When the handle scope object is deleted at run-time, all the indirect
handles created since the beginning of the handle scope’s lifetime are deleted
together, and the previous handle scope becomes the active handle scope. At any
point the GC can ask a handle scope to enumerate all the indirect handles it
refers to.

Indirect handles contain a pointer-sized value. That value points to a member of
an intermediate set called a handle block. Handle blocks are never moved in
memory, so pointers to a member of a handle block are always stable. Each member
of a handle block points to a JavaScript object.

V8 makes use of indirect handles to store Small Integer Objects (SMIs), that is
JavaScript integers that are not boxed on the heap. An important case is the SMI
0 and the null pointer: V8 encodes them in a way that allows them to be
efficiently differentiated. Indirect handles that have an internal value of NULL
represent a null pointer (and thus cannot be dereferenced to a handle block
member). Handle block members with an interior value whose least significant bit
is 0 encode a SMI; if the same bit is 1 a pointer is encoded.


\section{Gradually Migrating from Handles to Direct References}
\label{sec:migration}

\subsection{Direct object pointers}
\subsection{Conservative Stack Scanning}
\section{Evaluation}
\label{sec:evaluation}


\section{Related Work}
\label{sec:related}

The relative merits of direct pointers and handles have a long history in GC
and VMs, though quantitative comparisons are few in number. Generalising
somewhat, one technique or the other has tended to hold sway either at
different points in time, or within different communities.

Handles were commonly used in early Smalltalk VMs \laurie{let's cite at least
one Smalltalk VM using handles, ideally whichever is the earliest we know of}
\laurie{do we know why they were used in Smalltalk VMs? for moving i presume?}
and remain common in VMs that descend from that tradition (e.g.~Self,
HotSpot, Dart). \laurie{not sure if the rest of this is useful} HotSpot -- the now \emph{de facto}
standard JVM -- uses handles for C++ code \laurie{cite at least the glossary}.
Separately, HotSpot also uses a different kind of handles in the Java Native
Interface (JNI), its foreign function interface. Java objects are added to a
table of registered objects and accessed through a level of indirection when
used externally. The collector treats this table as an additional set of roots.
\laurie{i would not be surprised if the JNI handles are the same as the C++
handles}

\laurie{let's try relate this to our paper}
To the best of our knowledge, the most comprehensive study of handles
is~\cite{kalibera11handles}. They showed how moving handle-based VMs do not suffer
from \textit{copy reserve overhead}, where the old copy of a moved object must
be kept around until the mutator only holds references to the new object
location. Instead, with handles, the space used by evacuated objects can be
reused immediately as only the handle's address needs updating. With careful
optimisations, they showed that a handle-based system has same execution time
overheads as a Brooks-style compacting collector. Some of the ways they describe
that handles can be optimisated are: using \textit{fat handles} to store
commonly accessed header information along with the object pointer; grouping
handles of objects that live and die together to reduce fragmentation in handle
blocks; and short-circuiting handles for pinned objects.

Firefox's JavaScript engine SpiderMonkey uses handles in a similar fashion to
V8~\cite{spidermonkey}. \laurie{i'm not sure which bits of the rest of the
paragraph are different than V8.} Spidermonkey
developers must ensure that each pointer to a JavaScript object on the stack is
registered as root for garbage collection. Additional references to a JavaScript
object can then be created, which access it indirectly through the originally
rooted value. Rooted values are registered in lists based on scope, with
persistent handles available for longer living roots. Handles cannot be stored
on the heap as they could end up outliving their root. SpiderMonkey
uses a static analysis tool to make sure that raw pointers are not accidentally
put on the stack when a garbage collection can take place. The Gecko Rendering
engine is used in firefox. It is written in C++ and manages its DOM heap with
reference counting. It implements a cycle collector based on
\cite{bacon01concurrent}.

The use of direct pointers implicitly requires conservative scanning of at
least the stack. However, most (perhaps all) programming languages and most
(perhaps all) compilers have rules which suggest that conservative stack
scanning is undefined behaviour. Most obviously, there is no way of writing a
conservative stack scanner in C/C++ which is not undefined behaviour. In
practise, fortunately, conservative stack scanning `works', as perhaps best
evidenced by the long history of the Boehm-Demers-Weiser (BDW)
GC~\cite{boehm88garbage} which uses conservative scanning for the stack and
other possible location of GC roots (though note that the first conservative
scanning GC appears to have been~\cite{caplinger88memory}). BDW has been ported
to most platforms in its long history, and used by a wide variety of software
(including relatively modern software such as Inkscape): it is plausible that
its very existence has been the reason why conservative stack scanning
continues to be supported in practise across languages and compilers.

\jake{Should I mention oilpan here? Or is it too
"Chrome" to be considered related?} \laurie{i think it's fine to mention it, though 1 or 2 sentences is probably enough} Other conservative collectors for unmanaged
languages are the .

Safari's underlying engine WebKit (of which the JavaScript VM, JSC, is a part)
use direct pointers and conservative stack scanning~\cite{pizlo17riptide},
which is very similar to what we propose for V8 in this paper. WebKit has had
at least two different GCs over time (the current GC, \cite{pizlo17riptide},
mostly runs concurrently to JavaScript execution, similarly to V8), but this has not
changed the details relevant to this paper. Unlike V8, WebKit's GC never
moves objects, even across generations (instead using `sticky mark bits' that implicitly mark a given
object as belonging to a certain generation).
Where V8 only uses precise stack scanning
for C/C++ code, using stackmaps for JIT compiled code, WebKit uses conservative stack scanning for
both C/C++ code and JIT compiled code, marginally increasing the chances of
`accidental' object marking.

\laurie{is there anything novel about this paper w.r.t. handles? if it's just
that it uses handles to allow moving, that seems the same as all the earlier
handle-using systems?}
Compact-fit\cite{craciunas08compacting} is a compacting allocator which uses handles to allow objects to
move. It consists of two conceptual memory layers: the \textit{abstract address
space}; and the \textit{concrete address space}. Direct pointers to objects
allocated in the concrete address space are not possible. The application
operates on pointers to the abstract address space which are managed by handles.
Object headers have back-pointers to their canonical handle.

%TODO: Managed language collectors:
% - Fast CSS: https://users.cecs.anu.edu.au/~steveb/pubs/papers/consrc-oopsla-2014.pdf
% - Hybrid CSS: https://www.usenix.org/legacy/events/jvm01/full_papers/barabash/barabash.pdf
% - Forkscan Reclamation: https://dspace.mit.edu/bitstream/handle/1721.1/123336/forkscan-eurosys-17.pdf
% - Sound GC for C using taint analysis: https://dl.acm.org/doi/pdf/10.1145/3428244

\section{Conclusions}
\label{sec:conclusion}

\cite{jones16garbage}

\bibliographystyle{plain}
\bibliography{bib}

\end{document}
