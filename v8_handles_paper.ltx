%&v8_handles_paper_preamble
\endofdump

\begin{document}

\begin{abstract}
Many production virtual machines implemented in C++ like Oracle's HotSpot Java engine~\cite{}, Mozilla's SpiderMonkey JavaScript engine~\cite{}, and Google's V8 JavaScript engine~\cite{} wrap pointers to objects on the garbarge collected heap in so-called \emph{handles}.
Handles are used by the garbage collector to find all refencerenes to such on-heap objects on the stack when garbage collection is triggered during program execution with an active call stack of C++ functions.
A garbage collector is \emph{precise} if all on-heap references can be precisely identified by the garbage collector.
Otherwise it is \emph{conservative} which means that the garbage collector may find data values which look like references.
For such values a conservative garbage collector has to conservatively assume that they are references.

The performance impact of handles on performance is not well understood and discussed in literature and in practise.
%The performance merits of using handles or direct references for garbage collection have long been debated, but there are few published comparisons.
In this paper we study the difference between handles and direct references and provide concrete evidence of the performance differences between these two approaches by migrating a substantial portion of V8 from handles to direct references.
To support direct references in V8, we change V8's precise stack scanning mechanism to a conservative one and study the memory and performance overhead.
On the Speedometer browser benchmark~\cite{}, the use of direct references improves the total score by \laurie{X\%} while keeping the impact of conservative stack scanning on memory consumption and garbage collection pause times negligible.
\end{abstract}


\maketitle


\section{Introduction}

A major challenge for Garbage Collection (GC) is finding all the \emph{roots},
that is the starting set of references into the object graph. Ideally, GCs
would be able to precisely enumerate the root set. However, current languages
and compilers make this difficult, or impossible, as pointers
to objects can be `lost' on the call stack: to compensate, the call stack
must be \emph{conservatively scanned}, looking for pointers to objects on
the heap. This over-approximates the true root set as some non-pointers
may have a value which also happens to be a pointer to an object.
To avoid conservative scanning, one can use \emph{handles}, that
is wrappers around object references, such that the handles allow \emph{precise}
enumeration of the root set.

\laurie{V8 uses what i'm tentatively calling `partial handles`: that is, it
crates handles lazily, destroys them when it doesn't need them, and tries to
use direct references whenever it can. in contrast `comprehensive handles'
would never use direct references. do spidermonkey and v8 use partial or
comprehensive handles?}
\label{comprehensive_handles}
In this paper, we consider this long-standing implementation and design trade-off
in the context of programming language Virtual Machines (VMs). Some VMs
(e.g.~HotSpot, SpiderMonkey, V8) use handles; some (e.g.~JavaScriptCore and
those VMs using the Boehm-Demers-Weiser GC) use \emph{direct references}
(i.e.~`normal pointers'), and partial
or complete conservative scanning. There is little debate about the relative
ergonomics: handles are more difficult to use. We also now have good evidence
that conservative scanning of direct references tends to only slightly
over-approximate the root set~\cite{shahriyar14fast}. However, there is no
clear evidence for the run-time costs of handles relative to direct references
and conservative scanning. Without such an understanding, it is difficult to
state with confidence whether direct references or handles are the better trade-off.

In this paper we examine the widely used JavaScript VM V8, which has
been designed from its inception to use handles. Our hypothesis is
that moving from handles to direct references (and thus also conservative scanning) will improve V8's performance.
However, moving wholesale from handles to direct references is impractical on a
codebase of V8's size (~1.75m lines of code) \jake{does this include torque files?}, so our first challenge was
to find a practical means for gradually migrating parts of V8 from handles to
direct references (Section~\ref{sec:migration}). Having then migrated a
substantial portion of V8 from handles to direct references \laurie{can we give
a rough fraction/percentage?}, we then run several standard V8 benchmark
suites, and find that direct references improve performance by \laurie{X\%}
(Section~\ref{sec:evaluation}). We believe this validates our hypothesis in the
context of V8: it may also provide a useful example for other VMs when
considering direct references and handles.


\section{Background}
\label{sec:background}

In this section we provide a brief overview of direct references and handles in
the context of VMs. To help make this concrete, we do so for a
hypothetical VM, written in C, that implements an object orientated language.
In this VM, every language-level object is an instance of a \texttt{struct} called
\texttt{Obj}, which we will assume has a single field \texttt{data} of type
\texttt{int}. We assume that the VM contains a GC that runs in a thread
concurrently with other VM threads: thus the GC can free the memory of any
unreachable \texttt{Obj} at any point.


\subsection{Direct References}

The most `natural' way to program our hypothetical VM is to use direct
references. We assume that the GC exposes a single function \texttt{Obj
*gc\_new\_obj()}, which returns a pointer to a block of memory with a freshly
initialised \texttt{Obj}. When we want to create a new object, we call
\texttt{gc\_new\_obj}, assign the result to a local variable, and then operate
upon its \texttt{data} field:

\begin{lstlisting}[language=C]
Obj *n = gc_new_obj();
n.data = 1;
\end{lstlisting}

As this example suggests, `direct references' is our term for
what many would see as the `normal' way of programming in C. Unlike most
normal C programming, however, our VM must consider the concurrent GC:
it can run immediately after line 1 has executed, but
before line 2 has executed. If the GC were not to notice that \texttt{n}
is pointing to a live \texttt{Obj}, it would free that \texttt{Obj}'s memory,
causing the program to misbehave (e.g.~the program might segfault or overwrite
a portion of memory now used in another thread). In other words,
at that point in the program, \texttt{n} is a \emph{root}, that
is an entry point into the graph of objects created by the VM. For
our purposes, we can consider the root set to be all references to
objects stored in C-level variables, bearing
in mind that at run-time such variables may be stored as part of a
function frame on the C call stack\footnote{There are
other hiding places for such references, ranging from thread-locals to
registers to intermediate variables: for introductory purposes, these can be considered minor
variations on the C call stack problem.}.

The ideal, and universal, solution would be for C's language specification to
allow \emph{introspection} of a function's frame layout, telling it,
for example, where each local variable lives within a frame. For each
frame on the stack, the GC could then read the value of only those variables whose
compile-time type is \texttt{Obj*}, considering the objects they reference as roots.
Local variables of other types, which are not
of interest to the GC, would be ignored. This would allow the GC to \emph{precisely}
enumerate the GC roots (i.e.~to include all live objects as root while not
including any non-live objects as roots).
Unfortunately, no mainstream systems language defines an introspection
capability.

Some compilers instead offer the concept of \emph{stackmaps}, where
the compiler defines a way for a program to introspect the call stack at
specific locations. Stackmaps offer the same functionality as language-defined
introspection, but do so in a way that is not portable between compilers.
Unfortunately, stackmaps are not yet widely available. GCC does not
have any support for stackmaps. LLVM does have some stackmap support,
but (as some of this paper's authors have discovered in other work), it
is experimental, incomplete, and unsupported, with particular problems at
higher optimisation levels. \jake{There is also the statepoint author's article
on how the old conservative gc.root mechanism should be favoured for GC stuff in
LLVM. Not sure if that's worth citing?} \laurie{remind me what that mechanism
does: is it just stackmaps in disguise?} \jake{it's a way of escaping an alloca
in LLVM to some GC pass that you write yourself (which could be stackmaps or
some other mechanism).}

In practise, therefore, VMs using direct references have to turn to
\emph{conservative scanning}, where the C call stack is exhaustively examined for
pointers to instances of \texttt{Obj}. In order for this to work, the GC must
know at what address a thread's stack began, and what address the stack is
currently at. Each aligned word on the stack is then checked to see whether
it references an instance of \texttt{Obj}: if it does, that \texttt{Obj} is
considered a root. Depending on the GC, checking whether an arbitrary word is a
pointer to an \texttt{Obj} can be fairly expensive \laurie{cite?}. Conservative
scanning also inherently
over-approximates the root set, because random words on the stack may
accidentally point to an \texttt{Obj}, keeping it alive longer than necessary.
Fortunately, in practise relatively few objects are kept alive unnecessarily long:
the most extensive study we know of suggests the false detection rate
in Java programs is under 0.01\% of live objects~\cite{shahriyar14fast}.

Objects identified as live via conservative scanning must also be pinned in
memory. Fully conservative GCs, that is GCs who conservatively scan all parts
of memory, from the call stack to the heap, (e.g.~the Boehm-Demers-Weiser
GC~\cite{boehm88garbage}) are fundamentally unable to move any objects in
memory. Most conservative GCs are semi-conservative, that is most references to
objects are determined precisely, with only some roots discovered
conservatively. Semi-conservative GCs must temporarily pin those objects
identified as live by conservative scanning, because they cannot know whether
such references can be safely rewritten or not.

Conservative scanning also occupies an odd position in software: technically speaking, the
way it works violates the rules of most languages, most compilers, and most
operating systems.
In addition, programming techniques which rely on obfuscating pointers
(e.g.~using XOR lists) must be avoided, as they can hide roots from the GC.
However, because conservative scanning is widely used (e.g.~the well-known
Boehm-Demers-Weiser GC~\cite{boehm88garbage} and WebKit~\cite{pizlo17riptide})
any software that breaks it tends to be rapidly fixed \laurie{cite the word-splitting bug}.


\subsection{Handles}
\label{handles_general}

An alternative approach to direct references and conservative scanning
has become known as handles. These were first first introduced in
recognisable form by~\cite{brooks84trading}, though the term `handles' was only
used later. Modern VMs use handles in two distinct ways: in this section
we will consider \emph{comprehensive handles}, as found in~\cite{kalibera11handles}
(in Section~\ref{handles_in_v8} we will consider the other kind of handles).

Comprehensive handles add a level of indirection to all object references, with
the indirection being the `handle'. Handles are stored at a fixed point in
memory, with one handle per object. In the context of our hypothetical
VM, this means that we never store references to \texttt{Obj} directly, instead
storing references to a \texttt{Handle} struct. When the VM wants to access an
\texttt{Obj} it must \emph{tag} the corresponding \texttt{Handle}; this informs
the GC that the \texttt{Handle} is a root. When the VM is finished with the
\texttt{Obj} it must untag the corresponding \texttt{Handle}. We maintain a tag
count for each \texttt{Handle}, as it may be tagged multiple times before being
untagged: when the tag count goes to zero, the \texttt{Handle} is no longer a
root.

Our hypothetical GC needs three altered/new functions: \texttt{Handle
*gc\_new\_obj()} returns a pointer to a handle, where the handle points to a
freshly initialised \texttt{Obj}; \texttt{Obj *tag(Handle *)} which increments
a handle's tag count by one and returns a pointer to the underlying
\texttt{Obj}; and \texttt{void untag(Handle *)} which decrement the handle's
tag count by one. For example:

\begin{lstlisting}[language=C]
Handle *h = gc_new_obj();
Obj *o = tag(h);
n.data = 1;
untag(h);
\end{lstlisting}

Handles have important advantages. First, tagging and untagging allows
the GC to precisely determine the root set by iterating over all handles
and considering as a root any handle with a tag count greater than 0.
Second, handles are fully portable, do not trifle with undefined behaviour,
and require no explicit language or compiler support.
Third, any \texttt{Handle} with a zero tag count can have its
underlying \texttt{Obj} safely moved. In other words, handles
make it trivial to write precise, (almost fully) moving GCs. Comprehensive handles also
have the virtue that moving an \texttt{Obj} requires only updating its
corresponding \texttt{Handle}.

There are however disadvantages. First, any handle API is easy to misuse:
forgetting to \texttt{tag} a handle or \texttt{untag}ing a handle twice leads
to undefined behaviour. Finding such API misuse is notoriously hard, and VMs
such as V8 have developed home-grown linters that scan for obvious API misuse,
though none that we know of can catch all possible kinds of API misuse. Second,
handles' double level of indirection implies at least some performance loss
relative to the single indirection of direct references. Third, handles have
additional run-time costs beyond those of double indirection: each handle
consumes memory; since handles cannot move, they can cause memory
fragmentation; and tagging / untagging a handle requires memory reads and writes.


\section{Handles in V8}

V8 is a widely used JavaScript VM written in C++, most commonly known as the
Chrome browser's JavaScript VM, though it can also be used as a standalone
application. In this section we introduce some general V8 background, before
describing V8's use of handles.


\subsection{V8 background}

A single instance of V8 can safely run many unrelated JavaScript applications by
sandboxing them in separate execution environments known as \emph{isolates}.
In a practical sense, an isolate is an individual VM instance with its own
runtime (including its own instance of the V8 GC).
JavaScript is a single-threaded language with an event loop. \jake{TODO: explain
how this can result in stackless GCs}.

The GC in V8 is generational.
The JavaScript heap is split into young and old generations with objects
allocated in the young generation first\footnote{The weak-generational
hypothesis doesn't hold for some objects.
In such cases, they can be allocated directly in the old generation to remove
the cost of copying them later (a process known as \textit{pretenuring})}.
distinct sections for young and old object collection. The smaller young
generation is a Cheney style semi-space scavenger \laurie{cite} where
\textit{tospace} and \textit{fromspace} are contiguous chunks of memory that
young objects are bump allocated in.
When fromspace is full, live objects are moved to tospace (or promoted to the
old generation if they've been moved once already).
This process repeats, with the notion of tospace and fromspace flipped.

The old generation is a mark-sweep-compact collector.
Marking is performed concurrently to the main thread of JavaScript execution to
reduce pause times.
\jake{TODO where does incremental marking fit in here} This requires the use of
Dijsktra style write barriers when object fields are written to on the main
thread.
Sweeping is also performed concurrently to the main thread and makes use of
parallel worker threads.
Surviving objects are then compacted to reduce memory fragmentation.
Compaction is not done concurrently to the main thread, however, in Chrome it
makes use of idle time to reduce the impact of the GC pause.


\subsection{Handles in V8}
\label{handles_in_v8}

V8 uses handles to determine the root set of objects. Unlike the simple
VM described in \cref{comprehensive_handles}, V8 uses \emph{partial handles}:
that is, it uses direct references in those places where it can precisely track
them (e.g.~object slots), and handles in those places where it would otherwise
lose track of roots (e.g.~stack references). Although there are various kinds
of handles inside V8 \laurie{can we quickly
enumerate all the types of handles? are they different internally, or just
in the way they're used?} \jake{There are different handles both internally and
externally. Internally there are `root handles`, which point to roots in the
isolate (e.g. the Oddball, true and false objects, etc), these are used the same
way as regular handles (perhaps these are not worth mentioning). Then, at the API layer, there are: persistent handles,
eternals, and traced reference handles. Their names are somewhat explanatory but
the common difference between them and regular handles is that they are not
managed by handle scopes}we will solely consider those handles used by C++ code
to manipulate objects on the JavaScript heap.

Comprehensive handles as described in \cref{comprehensive_handles} persist
throughout a VM's lifetime, with each heap object having a single handle
pointing to it. In contrast, V8's partial handles are temporary, being
regularly created and destroyed: any object may, over its lifetime, have
multiple handles pointing to it. This has a significant impact on the way
handles are used within V8.

In essence, when V8's C++ code wishes to operate on a JavaScript object, it
must create a handle to it, destroying that handle when it is finished. This
can be thought of as a kind of `lock': the handle guarantees that the object
is kept alive while C++ code works upon object, without having to worry that
pointers to the object will be `lost' on the C++ call stack. As with other VMs
using this style of partial handles, V8 faces two challenges: how to make
partial handles ergonomic for the programmer; and how to make their regular
creation and destruction fast.

Since V8's C++ code uses partial handles extensively, the ergonomics of partial
handles are vital, both for correctness and code readability. V8's basic
mechanism to aid ergonomics is the \emph{handle scope} which stores handles.
Any V8 code can create a new handle scope, which is pushed onto a stack: the
most recently created handle scope is the `current' handle scope. C++'s RAII
mechanism is used to automatically destroy handle scopes: destroying the handle
scope also destroys all the handles created while that handle scope was active.
All access to heap objects is via an API that returns a direct pointer to a
heap object, while implicitly adding a handle to that object to the current
handle scope.

Handle scopes ensure that C++ code dealing with objects remains relatively
terse, and reduces several opportunities for programmer mistakes. However, C++
code must carefully ensure that it does not leak a direct pointer to an object
beyond the lifetime of the handle scope that references that object --- doing
so causes undefined behaviour. V8 has various `lints' to detect many such
mistakes \laurie{can we give a small example?} \jake{of a bug that made it into
release which was patched?}, but they cannot capture all
possible misuses: some misuses are later detected in debug builds, but some
misuses end up in release code, where they can become a significant security
concern.

\begin{figure}
\begin{lstlisting}[language=C++,
  caption={A simplified example of V8's C++ code, showing the use of handles.
  \texttt{main} creates a handle scope (line 2), and then calls \texttt{foo}
  which creates a further handle scope (line 7). Two new heap objects are
  created, each of which produces a handle (lines 8 and 9), ensuring that both
  objects are considered as roots. \texttt{foo} cannot directly return a handle
  to its caller, as that handle will be automatically destroyed when the handle
  scope is destroyed by RAII at the end of the function call. The
  \texttt{CloseAndEscape} method adds a new handle to \texttt{main}'s handle
  scope pointing to the \texttt{"a"} string, and passes a reference to that
  handle to the caller, allowing the underlying object to safely `escape' the
  handle scope it was created in.},
  label=handles_example]
void main() {
  HandleScope scope(GetIsolate());
  Handle<String> str = foo();
}

Handle<String> foo() {
  HandleScope scope(GetIsolate());
  Handle<String> a = NewString("a");
  Handle<String> b = NewString("b");
  return scope.CloseAndEscape(a);
}
\end{lstlisting}
\end{figure}

\cref{handles_example} shows a simplified snipped of V8's C++ code,
demonstrating how handle scopes interact. In this example, two handle scopes
are created, with the second handle scope wanting to return a handle that
outlives its handle scope. Handle scopes expose a \texttt{CloseAndEscape}
method which allow a handle to be safely moved to the parent handle scope.

Handle scopes are an important performance optimisation, since destroying
a handle scope causes its backing storage containing multiple handles
to be destroyed in one go: neither individual deallocation nor any form
of handle compaction is necessary.

\laurie{this next bit is me inferring from a half-forgotten conversation}
\jake{it's correct though :)}A
further optimisation is based on the observation that within a given handle
scope it is common for the same object to be referenced multiple times.
Although it is always correct to create multiple handles to the same object, it
is inefficient, since each handle requires memory, requiring the storage area
pointed to by a handle scope to be enlarged. When a handle for an object is
requested, V8 thus searches the current handle scope to see if an existing
handle to that object is present, only creating a new handle if none exists.
\laurie{is this just a linear scan?} \jake{it is, yes}

\jake{Deleted the part below on Blink as an API consumer and replaced it with
this, not sure where it goes, it could even be folded into the first paragraph}
The handle scope rules must be followed both inside the V8 codebase and also by
embedders who wish to access the JavaScript heap. To avoid exposing too many
internal details, V8's embedder API exposes a stripped down version of handles
and handle scopes which mirrors its internal implementation. For legacy reasons,
handles exposed to embedders are referred to as locals, while inside V8 they are
still called handles.

% dump
\begin{itemize}
  \item There's many different kind of handles in V8. They have two purposes: (a) allow the GC to find those object references and (b) allow the GC to relocate objects.
  \item In V8, handles are an explicit C++ mechanism/construct to maintain this information for the GC
  \item There's root handles (should probably have a different name) that that maintain this information per handle (costly, but flexible as each handle can be created/destroyed individually) -- the paper doesn't care about those
  \item There's handles (the interesting ones) that are bound to handle blocks which are maintained in a chain
  \item The chain itself is dynamic (the list of blocks depends on branches taken at runtime)
  \item The chain is mostly maintained via leveraging C++ lexical scopes and using RAII to add and remove blocks. Used this way, the handle scopes create precise stack maps.
  \item Handles automatically register themselves in the current active scope by allocating one entry in such a block
  \item A handle always refers to an object via the handle block.
  \item The top of the dynamic chain is known to the GC. The top is identified by a single V8 isolate.
  \item This way the GC can (a) find such handles and (b) relocate them
  \item This is much cheaper than the individual root handle version but comes with the restriction to (a) require setting up handle scopes in some stack-like fashion and (b) not using handles that have had their scopoe closed and block removed
  \item Using a handle that has been invalidated (scopes has been closed and thus block removed) is undefined behavior and results in (likely) crashes in debug builds
\end{itemize}

\section{Gradually Migrating from Handles to Direct References}
\label{sec:migration}

\subsection{Direct object pointers}

V8 makes use of indirect handles to store Small Integer Objects (SMIs), that is
JavaScript integers that are not boxed on the heap. An important case is the SMI
0 and the null pointer: V8 encodes them in a way that allows them to be
efficiently differentiated. Indirect handles that have an internal value of NULL
represent a null pointer (and thus cannot be dereferenced to a handle block
member). Handle block members with an interior value whose least significant bit
is 0 encode a SMI; if the same bit is 1 a pointer is encoded.

\subsection{Conservative Stack Scanning}
\section{Evaluation}
\label{sec:evaluation}

89\% of garbage collections in Chrome are happening without a stack when we are on the message loop.
Therefore making stack scanning conservative may not be an issue in practise.
Add Speedometer numbers how often we finalize with a stack there.
Maybe add browsing benchmark numbers to confirm impact\hannes{discuss with the team}.

\makeatletter
\newcommand*\ExpandableInput[1]{\@@input#1 }
\makeatother

 \begin{figure*}[t]
     \begin{tabular}{lll}
 \toprule
         Benchmark & HandlesMinGC (ms) & DirectPointersMinGc (ms) \\
 \midrule
\ExpandableInput{./table_no_gc}
 \bottomrule
 \end{tabular}
\caption{The mean results from 100 iterations of the Speedometer2.1 benchmark suite
    Chrome. Both the handle and direct pointer configurations are setup to fill
    the full 4GiB heap before triggering GC. They both trigger a single GC only
    on each iteration of Speedometer2.1. The DirectPointersMinGc configuration
    uses conservative stack scanning to find the rootset for GC. They are both
    running with a single generation heap.}
\end{figure*}

\makeatletter
\newcommand*\ExpandableInputTwo[1]{\@@input#1 }
\makeatother

 \begin{figure*}[t]
     \begin{tabular}{lll}
 \toprule
         Benchmark & HandlesNoStackCompact (ms) & DirectPointersNoStackCompact (ms) \\
 \midrule
\ExpandableInputTwo{./table_no_stack_compact}
 \bottomrule
 \end{tabular}
\caption{The mean results from 30 iterations of the Speedometer2.1 benchmark
    suite on Chrome. Both the handle and direct pointer configurations are setup to
    not compact the heap when there are roots on the stack. The
    DirectPointersNoStackCompact configuration uses conservative stack
    scanning to find the rootset for GC. They are both running with a single
    generation heap.}
\end{figure*}

\section{Related Work}
\label{sec:related}

The relative merits of direct pointers and handles have a long history in GC
and VMs, though quantitative comparisons are few in number. Generalising
somewhat, one technique or the other has tended to hold sway either at
different points in time, or within different communities.

Handles were commonly used in early Smalltalk VMs \laurie{let's cite at least
one Smalltalk VM using handles, ideally whichever is the earliest we know of}
\laurie{do we know why they were used in Smalltalk VMs? for moving i presume?}
and remain common in VMs that descend from that tradition (e.g.~Self,
HotSpot, Dart). \laurie{not sure if the rest of this is useful} HotSpot -- the now \emph{de facto}
standard JVM -- uses handles for C++ code \laurie{cite at least the glossary}.
Separately, HotSpot also uses a different kind of handles in the Java Native
Interface (JNI), its foreign function interface. Java objects are added to a
table of registered objects and accessed through a level of indirection when
used externally. The collector treats this table as an additional set of roots.
\laurie{i would not be surprised if the JNI handles are the same as the C++
handles}

\laurie{let's try relate this to our paper}
To the best of our knowledge, the most comprehensive study of handles
is~\cite{kalibera11handles}. They showed how moving handle-based VMs do not suffer
from \textit{copy reserve overhead}, where the old copy of a moved object must
be kept around until the mutator only holds references to the new object
location. Instead, with handles, the space used by evacuated objects can be
reused immediately as only the handle's address needs updating. With careful
optimisations, they showed that a handle-based system has same execution time
overheads as a Brooks-style compacting collector. Some of the ways they describe
that handles can be optimisated are: using \textit{fat handles} to store
commonly accessed header information along with the object pointer; grouping
handles of objects that live and die together to reduce fragmentation in handle
blocks; and short-circuiting handles for pinned objects.

Firefox's JavaScript engine SpiderMonkey uses handles in a similar fashion to
V8~\cite{spidermonkey}. \laurie{i'm not sure which bits of the rest of the
paragraph are different than V8.} Spidermonkey
developers must ensure that each pointer to a JavaScript object on the stack is
registered as root for garbage collection. Additional references to a JavaScript
object can then be created, which access it indirectly through the originally
rooted value. Rooted values are registered in lists based on scope, with
persistent handles available for longer living roots. Handles cannot be stored
on the heap as they could end up outliving their root. SpiderMonkey
uses a static analysis tool to make sure that raw pointers are not accidentally
put on the stack when a garbage collection can take place. The Gecko Rendering
engine is used in firefox. It is written in C++ and manages its DOM heap with
reference counting. It implements a cycle collector based on
\cite{bacon01concurrent}.

The use of direct pointers implicitly requires conservative scanning of at
least the stack. However, most (perhaps all) programming languages and most
(perhaps all) compilers have rules which suggest that conservative stack
scanning is undefined behaviour. Most obviously, there is no way of writing a
conservative stack scanner in C/C++ which is not undefined behaviour. In
practise, fortunately, conservative stack scanning `works', as perhaps best
evidenced by the long history of the Boehm-Demers-Weiser (BDW)
GC~\cite{boehm88garbage} which uses conservative scanning for the stack and
other possible location of GC roots (though note that the first conservative
scanning GC appears to have been~\cite{caplinger88memory}). BDW has been ported
to most platforms in its long history, and used by a wide variety of software
(including relatively modern software such as Inkscape): it is plausible that
its very existence has been the reason why conservative stack scanning
continues to be supported in practise across languages and compilers.

\jake{Should I mention oilpan here? Or is it too
"Chrome" to be considered related?} \laurie{i think it's fine to mention it, though 1 or 2 sentences is probably enough} Other conservative collectors for unmanaged
languages are the .

Safari's underlying engine WebKit (of which the JavaScript VM, JSC, is a part)
use direct pointers and conservative stack scanning~\cite{pizlo17riptide},
which is very similar to what we propose for V8 in this paper. WebKit has had
at least two different GCs over time (the current GC, \cite{pizlo17riptide},
mostly runs concurrently to JavaScript execution, similarly to V8), but this has not
changed the details relevant to this paper. Unlike V8, WebKit's GC never
moves objects, even across generations (instead using `sticky mark bits' that implicitly mark a given
object as belonging to a certain generation).
Where V8 only uses precise stack scanning
for C/C++ code, using stackmaps for JIT compiled code, WebKit uses conservative stack scanning for
both C/C++ code and JIT compiled code, marginally increasing the chances of
`accidental' object marking.

\laurie{is there anything novel about this paper w.r.t. handles? if it's just
that it uses handles to allow moving, that seems the same as all the earlier
handle-using systems?}
Compact-fit\cite{craciunas08compacting} is a compacting allocator which uses handles to allow objects to
move. It consists of two conceptual memory layers: the \textit{abstract address
space}; and the \textit{concrete address space}. Direct pointers to objects
allocated in the concrete address space are not possible. The application
operates on pointers to the abstract address space which are managed by handles.
Object headers have back-pointers to their canonical handle.

%TODO: Managed language collectors:
% - Fast CSS: https://users.cecs.anu.edu.au/~steveb/pubs/papers/consrc-oopsla-2014.pdf
% - Hybrid CSS: https://www.usenix.org/legacy/events/jvm01/full_papers/barabash/barabash.pdf
% - Forkscan Reclamation: https://dspace.mit.edu/bitstream/handle/1721.1/123336/forkscan-eurosys-17.pdf
% - Sound GC for C using taint analysis: https://dl.acm.org/doi/pdf/10.1145/3428244

\section{Conclusions}
\label{sec:conclusion}

\cite{jones16garbage}

\bibliographystyle{plain}
\bibliography{bib}

\end{document}
